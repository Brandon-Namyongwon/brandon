{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "https://github.com/Brandon-Namyongwon/brandon/blob/main/fastcampus_classifiacation.ipynb",
      "authorship_tag": "ABX9TyPkeLTfHEtZej5pBEmEJ4Br",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brandon-Namyongwon/brandon/blob/main/fastcampus_classifiacation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dusEDMKm9iqG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact\n",
        "\n",
        "random_seed = 2022\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "4cpzEFv8DygQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_image_files(data_dir, sub_dir):\n",
        "    image_format = [\"jpeg\", \"jpg\", \"png\"]\n",
        "\n",
        "    image_files = []\n",
        "    images_dir = os.path.join(data_dir, sub_dir)\n",
        "    for file_path in os.listdir(images_dir):\n",
        "        if file_path.split(\".\")[-1] in image_format:\n",
        "            image_files.append(os.path.join(sub_dir, file_path))\n",
        "    return image_files"
      ],
      "metadata": {
        "id": "8GgEfL4gna4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/fastcampus/Part3. 실습/Covid19-dataset/train\"\n",
        "\n",
        "normals_list = list_image_files(data_dir, \"Normal\")\n",
        "covids_list = list_image_files(data_dir, \"Covid\")\n",
        "pneumonias_list = list_image_files(data_dir, \"Viral Pneumonia\")"
      ],
      "metadata": {
        "id": "lw4OKF5boYn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "VelO8Vh9oer7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_RGB_image(data_dir, file_name):\n",
        "    image_file = os.path.join(data_dir, file_name)\n",
        "    image = cv2.imread(image_file)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image"
      ],
      "metadata": {
        "id": "lYb1oudBokPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact"
      ],
      "metadata": {
        "id": "iCmA-18joooR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_num_files = min(len(normals_list), len(covids_list), len(pneumonias_list))\n",
        "\n",
        "@interact(index=(0, min_num_files-1))\n",
        "def show_samples(index=0):\n",
        "    normal_image = get_RGB_image(data_dir, normals_list[index])\n",
        "    covid_image = get_RGB_image(data_dir, covids_list[index])\n",
        "    pneumonia_image = get_RGB_image(data_dir, pneumonias_list[index])\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(131)\n",
        "    plt.title(\"Normal\")\n",
        "    plt.imshow(normal_image)\n",
        "    plt.subplot(132)\n",
        "    plt.title(\"Covid\")\n",
        "    plt.imshow(covid_image)\n",
        "    plt.subplot(133)\n",
        "    plt.title(\"Pneumonia\")\n",
        "    plt.imshow(pneumonia_image)\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "UuXG4T8moq0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/fastcampus/Part3. 실습/Covid19-dataset/train\"\n",
        "class_list = [\"Normal\", \"Covid\", \"Viral Pneumonia\"]"
      ],
      "metadata": {
        "id": "HLh33PaxosPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chest_dataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        normals = list_image_files(data_dir, \"Normal\")\n",
        "        covids = list_image_files(data_dir, \"Covid\")\n",
        "        pneumonias = list_image_files(data_dir, \"Viral Pneumonia\")\n",
        "\n",
        "        self.files_path = normals + covids + pneumonias\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_file = os.path.join(self.data_dir, self.files_path[index])\n",
        "        image = cv2.imread(image_file)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        target = class_list.index(self.files_path[index].split(os.sep)[-2])\n",
        "\n",
        "        target = class_list.index(self.files_path[index].split(os.sep)[0])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            target = torch.Tensor([target]).long()\n",
        "\n",
        "        return {\"image\":image, \"target\":target}"
      ],
      "metadata": {
        "id": "zql1ILIEpCfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dset = Chest_dataset(train_data_dir)"
      ],
      "metadata": {
        "id": "gUUTpSuMpcMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 200\n",
        "plt.title(class_list[dset[index][\"target\"]])\n",
        "plt.imshow(dset[index][\"image\"])"
      ],
      "metadata": {
        "id": "HM1vGUXrsJYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                         std=[0.5, 0.5, 0.5])\n",
        "])def build_dataloader(train_data_dir, val_data_dir):\n",
        "    dataloaders = {}\n",
        "    train_dset = Chest_dataset(train_data_dir, transformer)\n",
        "    dataloaders[\"train\"] = DataLoader(train_dset, batch_size=4, shuffle=True, drop_last=True)\n",
        "\n",
        "    val_dset = Chest_dataset(val_data_dir, transformer)\n",
        "    dataloaders[\"val\"] = DataLoader(val_dset, batch_size=1, shuffle=False, drop_last=False)\n",
        "    return dataloaders\n",
        "\n"
      ],
      "metadata": {
        "id": "5ED9PtIDsL33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dset = Chest_dataset(train_data_dir, transformer)"
      ],
      "metadata": {
        "id": "-ufkx9IKsXOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 200\n",
        "image = train_dset[index][\"image\"]\n",
        "label = train_dset[index][\"target\"]"
      ],
      "metadata": {
        "id": "JrDhdbWPscvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image.shape, label)"
      ],
      "metadata": {
        "id": "ugzpsXYWsesb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataloader(train_data_dir, val_data_dir):\n",
        "    dataloaders = {}\n",
        "    train_dset = Chest_dataset(train_data_dir, transformer)\n",
        "    dataloaders[\"train\"] = DataLoader(train_dset, batch_size=4, shuffle=True, drop_last=True)\n",
        "\n",
        "    val_dset = Chest_dataset(val_data_dir, transformer)\n",
        "    dataloaders[\"val\"] = DataLoader(val_dset, batch_size=1, shuffle=False, drop_last=False)\n",
        "    return dataloaders\n"
      ],
      "metadata": {
        "id": "wkV352dNskuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/fastcampus/Part3. 실습/Covid19-dataset/train\"\n",
        "val_data_dir = \"/content/drive/MyDrive/fastcampus/Part3. 실습/Covid19-dataset/test\"\n",
        "dataloaders = build_dataloader(train_data_dir, val_data_dir)"
      ],
      "metadata": {
        "id": "w30zzQjqsn7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, d in enumerate(dataloaders[\"train\"]):\n",
        "    if i == 0:\n",
        "        break"
      ],
      "metadata": {
        "id": "VDCD2V5Isyk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"target\"].shape"
      ],
      "metadata": {
        "id": "vJpcLPsPs00s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"target\"].squeeze()"
      ],
      "metadata": {
        "id": "f3_L-v1ks4FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg19(pretrained=True)"
      ],
      "metadata": {
        "id": "JVyqRUQxs6Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224), batch_size=1, device=\"cpu\")"
      ],
      "metadata": {
        "id": "TQJ1Itwts9b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(256, len(class_list)),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "TRYML_Ln4V9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8c9vPgV40NN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}